---
title: "R Notebook: Leveraging Sagemaker SDK from R"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 
```{r}
library(reticulate)
sagemaker <- import('sagemaker')
session <- sagemaker$Session()
bucket <- session$default_bucket()
```


```{r}
role_arn <- 'arn:aws:iam::349934754982:role/service-role/AmazonSageMaker-ExecutionRole-20180913T235776'
```


```{r}
system("wget http://dataminingconsultant.com/DKD2e_data_sets.zip")
system("unzip -o DKD2e_data_sets.zip")
```


```{r}
library(readr)
churn<- read_csv(file = './Data sets/churn.txt')
head(churn)
```


```{r}
for (i in colnames(churn)){
  colnames(churn)[colnames(churn) == i] <- gsub(" ", "", i) 
}
colnames(churn)[colnames(churn) == 'Churn?'] <- 'Churn'
colnames(churn)[colnames(churn) == "Int'lPlan"] <- 'IntlPlan'
print(colnames(churn))
```

```{r}
factor_vars<-c("AreaCode","State","IntlPlan","VMailPlan","Churn")
for(i in factor_vars) {
  churn[[i]] <- as.factor(churn[[i]])
}

summary(churn)
```
```{r}
#install.packages("ggcorrplot")
library('ggcorrplot')
corr <- cor(churn[,sapply(churn,is.numeric)])
ggcorrplot(corr, hc.order = TRUE, type = "lower",
     outline.col = "white")
```



```{r}
churn[,c('DayCharge', 'EveCharge', 'NightCharge', 'IntlCharge','Phone')] <- list(NULL)
head(churn)
```
```{r}
library(lattice)
library(caret)
```


```{r}
library('dplyr')
churn_train <- churn %>%
  sample_frac(size = 0.7)
churn <- anti_join(churn, churn_train)
churn_test <- churn%>%
  sample_frac(size = 0.5)
churn_valid <- anti_join(churn, churn_test)
```


```{r}
target<-'Churn'
train_sparse <- model.matrix(~.,churn_train[, colnames(churn_train) != target])
test_sparse <- model.matrix(~.,churn_test[, colnames(churn_test) != target])
valid_sparse <- model.matrix(~.,churn_valid[, colnames(churn_valid) != target])
```

```{r}
write.csv(train_sparse, 'churn_train.csv')
write.csv(valid_sparse, 'churn_valid.csv')
```




```{r}
s3_train <- session$upload_data(path = 'churn_train.csv', 
                                bucket = bucket, 
                                key_prefix = 'data')
s3_test <- session$upload_data(path = 'churn_valid.csv', 
                                bucket = bucket, 
                                key_prefix = 'data')
```

```{r}
s3_train_input <- sagemaker$s3_input(s3_data = s3_train,
                                     content_type = 'csv')
s3_valid_input <- sagemaker$s3_input(s3_data = s3_test,
                                     content_type = 'csv')
```

```{r}
container <- '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:1'
```

```{r}
s3_output <- paste0('s3://', bucket, '/output')
estimator <- sagemaker$estimator$Estimator(image_name = container,
                                           role = role_arn,
                                           train_instance_count = 1L,
                                           train_instance_type = 'ml.m5.large',
                                           train_volume_size = 30L,
                                           train_max_run = 3600L,
                                           input_mode = 'File',
                                           output_path = s3_output,
                                           output_kms_key = NULL,
                                           base_job_name = NULL,
                                           sagemaker_session = NULL)
```



```{r}
estimator$set_hyperparameters(num_round = 100L, objective='binary:logistic')
job_name <- paste('sagemaker-train-xgboost', format(Sys.time(), '%H-%M-%S'), sep = '-')
input_data <- list('train' = s3_train_input,
                   'validation' = s3_valid_input)
estimator$fit(inputs = input_data,
              job_name = job_name)
```

```{r}
factor_levels <- lapply(churn_train[, sapply(churn_train, is.factor), drop=FALSE],
                            function(x) {levels(x)})
```


```{r}
#install.packages("xgboost")
library('xgboost')
```
xgb <- xgboost(data = data.matrix(X[,-1]), 
 label = y, 
 eta = 0.1,
 max_depth = 15, 
 nround=25, 
 subsample = 0.5,
 colsample_bytree = 0.5,
 seed = 1,
 eval_metric = "merror",
 objective = "multi:softprob",
 num_class = 12,
 nthread = 3
)

```{r}
params <- list(booster = "gbtree", objective = "binary:logistic", eta=0.3, gamma=0, max_depth=6, min_child_weight=1, subsample=1, colsample_bytree=1)
xgb1 <- xgb.train (params = params, data = dtrain, nrounds = 80, watchlist=list(val=dtest,train=dtrain), print.every.n = 10, early.stop.round = 10, maximize = F , eval_metric = "error")
```


```{r}
xgbpred <- predict (xgb1,dtest)
xgbpred <- ifelse (xgbpred > 0.5,1,0)
```

```{r}
#confusion matrix
library(caret)
confusionMatrix (as.factor(xgbpred), as.factor(churn_test[[target]]))
#Accuracy - 86.54%` 

#view variable importance plot
mat <- xgb.importance (feature_names = colnames(dtrain),model = xgb1)
xgb.plot.importance (importance_matrix = mat[1:20]) 
```

